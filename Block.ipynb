{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Block.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"mount_file_id":"1BDURAyBXfPm52vaGma1GwolGKMK8khuY","authorship_tag":"ABX9TyOflMv9OIx76xASLVDjo0ms"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"YsIlwm0Ln6fp"},"source":["# 디렉토리 지정"]},{"cell_type":"code","metadata":{"id":"Ow9lk1Yaszqq"},"source":["cd /content/drive/MyDrive/projects/edge-ai/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-oF0nZtesmo5"},"source":["# 라이브러리 import"]},{"cell_type":"code","metadata":{"id":"pyO-PlmpsmYI"},"source":["import tensorflow as tf\r\n","\r\n","from keras.preprocessing import image\r\n","from keras import layers\r\n","from keras.models import Model, Sequential, load_model\r\n","from keras.applications import MobileNetV2\r\n","\r\n","import numpy as np\r\n","import pandas as pd\r\n","import matplotlib.pyplot as plt\r\n","import matplotlib\r\n","import seaborn as sns\r\n","from PIL import Image\r\n","import cv2\r\n","%matplotlib inline\r\n","\r\n","import keras.preprocessing\r\n","\r\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8qDBD7ZqoFRY"},"source":["# 데이터 불러오기"]},{"cell_type":"markdown","metadata":{"id":"0yonARa5oJ4Y"},"source":["* 데이터 설명: 조선소 3D 블록 데이터를 활용해 만든 모사 이미지 데이터셋\r\n","* 데이터 형태\r\n","    * X: 13 x 2700 x 1022 x 856\r\n","    * Y: 13 x 2700 x 1"]},{"cell_type":"markdown","metadata":{"id":"hWIu91Gsp0gX"},"source":["## 기초 경로 지정"]},{"cell_type":"code","metadata":{"id":"mmZ4YgitoHI2"},"source":["base_dir = \"/content/drive/MyDrive/projects/edge-ai/\"\r\n","img_dir = \"/content/drive/MyDrive/projects/edge-ai/BlockV3\"\r\n","test_dir = \"/content/drive/MyDrive/projects/edge-ai/BlockV2_test\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kMSYtUy_p55o"},"source":["## 이미지 데이터 경로 리스트 생성"]},{"cell_type":"code","metadata":{"id":"WYwhu29XpBc1"},"source":["block_list = os.listdir(img_dir) # 블록 리스트"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F3O-Z1PosO-z"},"source":["## 이미지 불러오기"]},{"cell_type":"code","metadata":{"id":"S9-ktmhHLU1l"},"source":["train_dataset = keras.preprocessing.image_dataset_from_directory(\r\n","    directory = img_dir, # 데이터가 있는 디렉토리 설정\r\n","    labels=\"inferred\",\r\n","    label_mode=\"int\",\r\n","    class_names=None,\r\n","    color_mode=\"grayscale\", # grayscale, rgb, rgba\r\n","    batch_size=32, \r\n","    image_size=(256, 256),\r\n","    shuffle=True,\r\n","    seed=1337,\r\n","    validation_split=0.2,\r\n","    subset=\"training\", \r\n","    interpolation=\"bilinear\",\r\n","    follow_links=False\r\n",")\r\n","\r\n","validation_dataset = keras.preprocessing.image_dataset_from_directory(\r\n","    directory = img_dir, # 데이터가 있는 디렉토리 설정\r\n","    labels=\"inferred\",\r\n","    label_mode=\"int\",\r\n","    class_names=None,\r\n","    color_mode=\"grayscale\", # grayscale, rgb, rgba\r\n","    batch_size=32, \r\n","    image_size=(256, 256),\r\n","    shuffle=True,\r\n","    seed=1337,\r\n","    validation_split=0.2,\r\n","    subset=\"validation\", \r\n","    interpolation=\"bilinear\",\r\n","    follow_links=False\r\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hee_OBC7sT61"},"source":["# 이미지 시각화"]},{"cell_type":"code","metadata":{"id":"ybdCvwaDsBLy"},"source":["plt.figure(figsize=(10, 10))\r\n","for images, labels in train_dataset.take(1):\r\n","    for i in range(9):\r\n","        ax = plt.subplot(3, 3, i+1)\r\n","        plt.imshow(images[i].numpy().astype(\"uint8\"))\r\n","        plt.title(int(labels[i]))\r\n","        plt.axis(\"off\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wPVk4wVTMdgJ"},"source":["# Data Argumentation\r\n","\r\n","이미지 데이터를 전처리하여 데이터량을 늘린다. 하지만 천지창조에서 이미 데이터를 늘려 나온 탓에 왠만하면 하지않는 것이 좋다."]},{"cell_type":"code","metadata":{"id":"bIKrBIm_s1EZ"},"source":["data_argumentation = keras.Sequential(\r\n","    [\r\n","        keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\r\n","        keras.layers.experimental.preprocessing.RandomRotation(0.1),\r\n","    ]\r\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lQ0cF9mJLtko"},"source":["plt.figure(figsize=(10, 10))\r\n","\r\n","for images, _ in train_dataset.take(1):\r\n","    for i in range(9):\r\n","        augmented_images = data_argumentation(images)\r\n","        ax = plt.subplot(3, 3,  i+1)\r\n","        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\r\n","        plt.axis(\"off\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TZPh23Y_QDCS"},"source":["# 신경망 모델 구성"]},{"cell_type":"code","metadata":{"id":"SSdKycItM18S"},"source":["def make_model(input_shape, num_classes):\r\n","    inputs = keras.Input(shape=input_shape)\r\n","    # Image augmentation block\r\n","    \r\n","    x = inputs\r\n","\r\n","    # Entry block\r\n","    x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(x)\r\n","    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\r\n","    x = layers.BatchNormalization()(x)\r\n","    x = layers.Activation(\"relu\")(x)\r\n","\r\n","    x = layers.Conv2D(64, 3, padding=\"same\")(x)\r\n","    x = layers.BatchNormalization()(x)\r\n","    x = layers.Activation(\"relu\")(x)\r\n","\r\n","    previous_block_activation = x  # Set aside residual\r\n","\r\n","    for size in [128, 256, 512, 728]:\r\n","        x = layers.Activation(\"relu\")(x)\r\n","        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\r\n","        x = layers.BatchNormalization()(x)\r\n","\r\n","        x = layers.Activation(\"relu\")(x)\r\n","        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\r\n","        x = layers.BatchNormalization()(x)\r\n","\r\n","        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\r\n","\r\n","        # Project residual\r\n","        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\r\n","            previous_block_activation\r\n","        )\r\n","        x = layers.add([x, residual])  # Add back residual\r\n","        previous_block_activation = x  # Set aside next residual\r\n","\r\n","    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\r\n","    x = layers.BatchNormalization()(x)\r\n","    x = layers.Activation(\"relu\")(x)\r\n","\r\n","    x = layers.GlobalAveragePooling2D()(x)\r\n","    if num_classes == 2:\r\n","        activation = \"sigmoid\"\r\n","        units = 1\r\n","    else:\r\n","        activation = \"softmax\"\r\n","        units = num_classes\r\n","\r\n","    x = layers.Dropout(0.5)(x)\r\n","    outputs = layers.Dense(units, activation=activation)(x)\r\n","    return keras.Model(inputs, outputs)\r\n","\r\n","\r\n","model = make_model(input_shape=(256, 256) + (1,), num_classes=12)\r\n","keras.utils.plot_model(model, show_shapes=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8gnBSlRdlcrj"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5NacbDukSuvE"},"source":["# MobileNetV2"]},{"cell_type":"code","metadata":{"id":"rl0UtCqbn2uX"},"source":["\"\"\"MobileNet v2 models for Keras.\r\n","# Reference\r\n","- [Inverted Residuals and Linear Bottlenecks Mobile Networks for\r\n","   Classification, Detection and Segmentation]\r\n","   (https://arxiv.org/abs/1801.04381)\r\n","\"\"\"\r\n","\r\n","\r\n","from keras.models import Model\r\n","from keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dropout\r\n","from keras.layers import Activation, BatchNormalization, Add, Reshape, DepthwiseConv2D\r\n","from keras.utils.vis_utils import plot_model\r\n","\r\n","from keras import backend as K\r\n","\r\n","\r\n","def _make_divisible(v, divisor, min_value=None):\r\n","    if min_value is None:\r\n","        min_value = divisor\r\n","    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\r\n","    # Make sure that round down does not go down by more than 10%.\r\n","    if new_v < 0.9 * v:\r\n","        new_v += divisor\r\n","    return new_v\r\n","\r\n","\r\n","def relu6(x):\r\n","    \"\"\"Relu 6\r\n","    \"\"\"\r\n","    return K.relu(x, max_value=6.0)\r\n","\r\n","\r\n","def _conv_block(inputs, filters, kernel, strides):\r\n","    \"\"\"Convolution Block\r\n","    This function defines a 2D convolution operation with BN and relu6.\r\n","    # Arguments\r\n","        inputs: Tensor, input tensor of conv layer.\r\n","        filters: Integer, the dimensionality of the output space.\r\n","        kernel: An integer or tuple/list of 2 integers, specifying the\r\n","            width and height of the 2D convolution window.\r\n","        strides: An integer or tuple/list of 2 integers,\r\n","            specifying the strides of the convolution along the width and height.\r\n","            Can be a single integer to specify the same value for\r\n","            all spatial dimensions.\r\n","    # Returns\r\n","        Output tensor.\r\n","    \"\"\"\r\n","\r\n","    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\r\n","\r\n","    x = Conv2D(filters, kernel, padding='same', strides=strides)(inputs)\r\n","    x = BatchNormalization(axis=channel_axis)(x)\r\n","    return Activation(relu6)(x)\r\n","\r\n","\r\n","def _bottleneck(inputs, filters, kernel, t, alpha, s, r=False):\r\n","    \"\"\"Bottleneck\r\n","    This function defines a basic bottleneck structure.\r\n","    # Arguments\r\n","        inputs: Tensor, input tensor of conv layer.\r\n","        filters: Integer, the dimensionality of the output space.\r\n","        kernel: An integer or tuple/list of 2 integers, specifying the\r\n","            width and height of the 2D convolution window.\r\n","        t: Integer, expansion factor.\r\n","            t is always applied to the input size.\r\n","        s: An integer or tuple/list of 2 integers,specifying the strides\r\n","            of the convolution along the width and height.Can be a single\r\n","            integer to specify the same value for all spatial dimensions.\r\n","        alpha: Integer, width multiplier.\r\n","        r: Boolean, Whether to use the residuals.\r\n","    # Returns\r\n","        Output tensor.\r\n","    \"\"\"\r\n","\r\n","    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\r\n","    # Depth\r\n","    tchannel = K.int_shape(inputs)[channel_axis] * t\r\n","    # Width\r\n","    cchannel = int(filters * alpha)\r\n","\r\n","    x = _conv_block(inputs, tchannel, (1, 1), (1, 1))\r\n","\r\n","    x = DepthwiseConv2D(kernel, strides=(s, s), depth_multiplier=1, padding='same')(x)\r\n","    x = BatchNormalization(axis=channel_axis)(x)\r\n","    x = Activation(relu6)(x)\r\n","\r\n","    x = Conv2D(cchannel, (1, 1), strides=(1, 1), padding='same')(x)\r\n","    x = BatchNormalization(axis=channel_axis)(x)\r\n","\r\n","    if r:\r\n","        x = Add()([x, inputs])\r\n","\r\n","    return x\r\n","\r\n","\r\n","def _inverted_residual_block(inputs, filters, kernel, t, alpha, strides, n):\r\n","    \"\"\"Inverted Residual Block\r\n","    This function defines a sequence of 1 or more identical layers.\r\n","    # Arguments\r\n","        inputs: Tensor, input tensor of conv layer.\r\n","        filters: Integer, the dimensionality of the output space.\r\n","        kernel: An integer or tuple/list of 2 integers, specifying the\r\n","            width and height of the 2D convolution window.\r\n","        t: Integer, expansion factor.\r\n","            t is always applied to the input size.\r\n","        alpha: Integer, width multiplier.\r\n","        s: An integer or tuple/list of 2 integers,specifying the strides\r\n","            of the convolution along the width and height.Can be a single\r\n","            integer to specify the same value for all spatial dimensions.\r\n","        n: Integer, layer repeat times.\r\n","    # Returns\r\n","        Output tensor.\r\n","    \"\"\"\r\n","\r\n","    x = _bottleneck(inputs, filters, kernel, t, alpha, strides)\r\n","\r\n","    for i in range(1, n):\r\n","        x = _bottleneck(x, filters, kernel, t, alpha, 1, True)\r\n","\r\n","    return x\r\n","\r\n","\r\n","def MobileNetv2(input_shape, k, alpha=1.0):\r\n","    \"\"\"MobileNetv2\r\n","    This function defines a MobileNetv2 architectures.\r\n","    # Arguments\r\n","        input_shape: An integer or tuple/list of 3 integers, shape\r\n","            of input tensor.\r\n","        k: Integer, number of classes.\r\n","        alpha: Integer, width multiplier, better in [0.35, 0.50, 0.75, 1.0, 1.3, 1.4].\r\n","    # Returns\r\n","        MobileNetv2 model.\r\n","    \"\"\"\r\n","    inputs = Input(shape=input_shape)\r\n","    \r\n","    x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(inputs)\r\n","\r\n","    first_filters = _make_divisible(32 * alpha, 8)\r\n","    x = _conv_block(x, first_filters, (3, 3), strides=(2, 2))\r\n","\r\n","    x = _inverted_residual_block(x, 16, (3, 3), t=1, alpha=alpha, strides=1, n=1)\r\n","    x = _inverted_residual_block(x, 24, (3, 3), t=6, alpha=alpha, strides=2, n=2)\r\n","    x = _inverted_residual_block(x, 32, (3, 3), t=6, alpha=alpha, strides=2, n=3)\r\n","    x = _inverted_residual_block(x, 64, (3, 3), t=6, alpha=alpha, strides=2, n=4)\r\n","    x = _inverted_residual_block(x, 96, (3, 3), t=6, alpha=alpha, strides=1, n=3)\r\n","    x = _inverted_residual_block(x, 160, (3, 3), t=6, alpha=alpha, strides=2, n=3)\r\n","    x = _inverted_residual_block(x, 320, (3, 3), t=6, alpha=alpha, strides=1, n=1)\r\n","\r\n","    if alpha > 1.0:\r\n","        last_filters = _make_divisible(1280 * alpha, 8)\r\n","    else:\r\n","        last_filters = 1280\r\n","\r\n","    x = _conv_block(x, last_filters, (1, 1), strides=(1, 1))\r\n","    x = GlobalAveragePooling2D()(x)\r\n","    x = Reshape((1, 1, last_filters))(x)\r\n","    x = Dropout(0.3, name='Dropout')(x)\r\n","    x = Conv2D(k, (1, 1), padding='same')(x)\r\n","\r\n","    x = Activation('softmax', name='softmax')(x)\r\n","    output = Reshape((k,))(x)\r\n","\r\n","    model = Model(inputs, output)\r\n","    # plot_model(model, to_file='images/MobileNetv2.png', show_shapes=True)\r\n","\r\n","    return model\r\n","\r\n","\r\n","if __name__ == '__main__':\r\n","    model = MobileNetv2((224, 224, 1), 12, 1.0)\r\n","    print(model.summary())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HSI4_p1FOGDY"},"source":["epochs = 30\r\n","\r\n","callbacks = [\r\n","    keras.callbacks.EarlyStopping(patience=3),\r\n","    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\", monitor='val_loss', save_best_only=True),\r\n","    keras.callbacks.TensorBoard(log_dir='./log'),\r\n","]\r\n","model.compile(\r\n","    optimizer=keras.optimizers.Adam(1e-4),\r\n","    loss=\"sparse_categorical_crossentropy\",\r\n","    metrics=[\"accuracy\"],\r\n",")\r\n","history = model.fit(\r\n","    train_dataset, epochs=epochs, callbacks=callbacks, validation_data=validation_dataset,\r\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rtSpNFXq8UVS"},"source":["plt.figure(figsize=(30, 30))\r\n","for i in [\"02_F11P\", \"04_F12C\"]:\r\n","    for j in range(1, 6):\r\n","        test_data = keras.preprocessing.image.load_img(\r\n","            os.path.join(test_dir, i, \"_{}.jpg\".format(j)), \r\n","            target_size=(224, 224),\r\n","            color_mode=\"grayscale\",\r\n","            interpolation=\"bilinear\"\r\n","        )\r\n","\r\n","\r\n","        img_array = keras.preprocessing.image.img_to_array(test_data)/255\r\n","        img_array = tf.expand_dims(img_array, 0)\r\n","\r\n","        predictions = model.predict(img_array)\r\n","        score = tf.nn.softmax(predictions)\r\n","\r\n","        \r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c6YqJzL2FVy3"},"source":["plt.scatter(range(1, 13), score)\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fDWWwezw9y99"},"source":["# Load the TensorBoard notebook extension\r\n","%load_ext tensorboard\r\n","\r\n","%tensorboard --logdir logs"],"execution_count":null,"outputs":[]}]}